#put residuals in vector "res":
res=residuals(nonlin)
#extract k value from regression "nonlin" and store in previously created vector "k":
k[i]=coef(nonlin)[1]#put predicted and residual values in array:
pred[,i]=pr
resid[,i]=res
#put observations in array "obs" for plotting later:
obs[,i]=Mt
}	#end of nls “for” loop
Osa.deco <- decomp %>%
arrange(age_code, mesh, litter_type, rep, days) %>%
aiP <- filter(age_code == 'a', mesh == 'i', litter_type == 'Primary') %>%
aiS <- filter(age_code == 'a', mesh == 'i', litter_type == 'Secondary')
?update
?update.package
??update.package
update.packages(dplyr)
update.packages()
library(dplyr)
packageVersion('dplyr')
update.packages()
# test, 'make proportional' function
#Devin's 'make_proportional' function
make_proportional <- function(x){out<-NULL;libs<-rowSums(x);
for(i in (1:nrow(x))){
out<-rbind(out,x[i,]*min(libs)/libs[i])
};return(out)
)
citation('stats')
source("http://chave.ups-tlse.fr/pantropical_allometry/readlayers.r")
latitude = 52.68
longitude=-52.68;latitude=4.08;coord=cbind(longitude,latitude)
coord
require(raster)
require(ncdf)
source("http://chave.ups-tlse.fr/pantropical_allometry/readlayers.r")
retrieve_raster('CWD', coord)
retrieve_raster('E', coord)
library(ggplot2)
sessionInfo()
##CAH Island GPP and NPP 2002-2010
##Paul C. Selmants December 17, 2014
rm(list=ls()) # reset R's brain
library(ggplot2) #load package 'ggplot2' to make graphs
library(dplyr) #load package 'dplyr' to summarize data within factors
#set the working directory
setwd("/Users/Selmants/Documents/Hawaii projects/USGS C Assessment/data/Fluxes/GPP/base/GPP_island_sum")
#Read .csv files into R
gpp_x <- read.csv('GPP_island_sum.csv')
npp_y <- read.csv('NPP_island_sum.csv')
#merge GPP and NPP into one dataframe
merge_xy <- merge(gpp_x, npp_y, by = c('Year', 'ISLAND', 'ZONE_CODE', 'COUNT', 'AREA'))
library(devtools)
srdb <- read.csv('https://raw.githubusercontent.com/bpbond/srdb/master/srdb-data.csv')
library(RCurl)
x <- getURL('https://raw.githubusercontent.com/bpbond/srdb/master/srdb-data.csv')
srdb <- read.csv(text = x)
head(srdb)
tail(srdb)
rm(list = ls())
library(RCurl)
library(dplyr)
x <- getURL('https://raw.githubusercontent.com/bpbond/srdb/master/srdb-data.csv')
srdb <- read.csv(text = x)
filter(srdb, Author = 'Litton')
filter(srdb, Author = Litton)
filter(srdb, Author == Litton)
filter(srdb, Author == 'Litton')
structure(srdb)
summary(srdb)
str(srdb)
filter(srdb, Ecosystem_type == 'Forest')
forest.srdb <- filter(srdb, Ecosystem_type == 'Forest')
str(forest.srdb)
forest.srdb <- filter(srdb, Ecosystem_type == 'Forest', Study_midyear > 2002)
str(forest.srdb)
forest.srdb <- filter(srdb, Ecosystem_type == 'Forest', Study_midyear < 2002, GPP >0.01)
str(forest.srdb)
##Soil Respiration database
##Paul Selmants
##December 22, 2014
rm(list = ls())
library(RCurl)
library(dplyr)
x <- getURL('https://raw.githubusercontent.com/bpbond/srdb/master/srdb-data.csv')
srdb <- read.csv(text = x)
head(srdb)
filter(Ecosystem_type == 'Forest', TBCA >0.001)
filter(srbd, Ecosystem_type == 'Forest', TBCA >0.001)
filter(srdb, Ecosystem_type == 'Forest', TBCA >0.001)
head(srdb)
filter(srdb, Ecosystem_type == "Forest", Litter_flux > 0.001)
str(srdb)
forest.srdb <- filter(srdb, Ecosystem_type == 'Forest', Litter_flux > 0.001)
str(forest.srdb)
##Soil Respiration database
##Paul Selmants
##December 22, 2014
rm(list = ls())
library(RCurl)
library(dplyr)
x <- getURL('https://raw.githubusercontent.com/bpbond/srdb/master/srdb-data.csv')
srdb <- read.csv(text = x)
head(srdb)
srdb.forest <- srdb %>%
group_by(Ecosystem_type) %>%
summarise(n = length(Ecosystem_type))
srdb.forest
tail(srdb)
srdb.forest <- srdb %>%
filter(Ecosystem_type == Forest) %>%
summarise(n = length(Biome))
srdb.forest <- srdb %>%
filter(Ecosystem_type = Forest) %>%
summarise(n = length(Biome))
srdb.forest <- srdb %>%
filter(grepl('Forest', Ecosystem_type)) %>%
summarise(n = length(Biome))
srdb.forest
srdb.forest <- srdb %>%
filter(grepl('Forest', Ecosystem_type)) %>%
group_by(Biome) %>%
summarise(n = length(Biome))
srdb.forest
library(ggplot2)
sessioninfo()
sessionInfo()
library(dplyr)
sessionInfo()
install(dplyr)
library(dplyr)
sessionInfo()
load('/Users/Selmants/Desktop/Tasmania.RData')
head(Tasmania)
tail(Tasmania)
install.packages('pryr')
f <- function(x) x^2
f
formals(f)
body(f)
f(2)
f(10)
c <- 10
c(c = c)
nums = rnorm(25, mean = 100, sd  = 15)
mean(nums)
sd(nums)
length(nums)
se <- sqrt(var(nums)/length(nums))
se
rm(se)
se
se <- function(x)
{}
se
rm(se)
se
se <- function(x)
{sqrt(x)/length(x)}
se(nums)
rm(se)
se
se = function(x)
{}
rm(se)
se
se <- function(x)
{sqrt(var(x)/length(x))}
se(nums)
nums <- rnorm(25, mean = 100, sd = 15)
mean(nums)
nums
sd(nums)
sem <- function(x)
{
sqrt(var(x)/length(x))
}
sem
ls
ls()
str(sem)
sem(nums)
class(sem)
sem
library(dplyr)
sessionInfo()
library(magrittr)
sessionInfo()
packageVersion('dplyr')
packageVersion('ggplot2')
library(dplyr)
library(ggplot2)
news(Version == "1.0.0", package = 'ggplot2')
search()
say <- function(what) system(sprintf('say "%s"', what))
say
devtools::install_github('hadley/readr')
library(readr)
library(dplyr)
data(warpbreaks)
summary(warpbreaks)
head(warpbreaks)
tail(warpbreaks)
library(dplyr)
descriptives(warpbreaks) %>%
groupby(wool, tension) %>%
summarize(mean = mean(breaks), sd = sd(breaks))%>%
round((mean, sd), 2)
descriptives(warpbreaks) %>%
groupby(wool, tension) %>%
summarize(mean = mean(breaks), sd = sd(breaks))
descriptives <- warpbreaks %>%
groupby(wool, tension) %>%
summarize(mean = mean(breaks), sd = sd(breaks))
descriptives <- warpbreaks %>%
group_by(wool, tension) %>%
summarize(mean = mean(breaks), sd = sd(breaks))
descriptives
descriptives <- warpbreaks %>%
summarize(mean = round(mean(breaks), 2) sd = round(sd(breaks),2)) %>%
descriptives <- warpbreaks %>%
group_by(wool, tension) %>%
summarise(mean = round(mean(breaks), 2), sd = round(sd(breaks), 2))
descriptives
library(knitr)
kable(descriptives)
myHTMLTable<-kable(descriptives,format='html',output=F)
write(myHTMLTable, file = 'table.html')
getwd()
low.phyla <- phyla %>%
filter(!grepl('Acidobacteria|Actinobacteria|Chloroflexi|Planctomycetes|Proteobacteria|WPS-2',
phylum)) %>%
group_by(MAT, plot) %>%
summarise(relabun.pct = sum(relabun.pct)) %>%
mutate(phylum = 'Other')
high.phyla <- phyla %>%
filter(grepl('Acidobacteria|Actinobacteria|Chloroflexi|Planctomycetes|Proteobacteria|WPS-2',
phylum)) %>%
select(MAT, plot, relabun.pct, phylum)
phylumfig <- merge(high.phyla, low.phyla, by = c('plot', 'MAT', 'phylum', 'relabun.pct'))
wUF.dm <- read.delim('weighted_unifrac_dm.txt', row.names = 1)
uwUF.dm <- read.delim('unweighted_unifrac_dm.txt', row.names = 1)
wUF.dm <- read.delim('weighted_unifrac_dm.txt', row.names = 1)
install.packages('readr')
setwd('~/Documents/Hawaii projects/bacteria_MAT')
require(readr)
read_delim('chao1.txt')
read_delim('chao1.txt', tab)
read_delim('chao1.txt', delim = tab)
read_delim(file = 'chao1.txt', delim = tab)
